{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe62561",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5adb11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:38:56.129267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 10:38:56.312234: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-20 10:38:56.382832: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-20 10:38:56.979172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/shinichi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-20 10:38:56.979237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/shinichi/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-20 10:38:56.979241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c1f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c27e0f",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291741c8",
   "metadata": {},
   "source": [
    "data is already augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b395ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"..\", \"yolo_preperation\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f156476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_yolo_data(data_dir, split, stride=1):\n",
    "    image_path = os.path.join(data_dir, \"images\", split)\n",
    "    label_path = os.path.join(data_dir, \"labels\", split)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for file_name in glob.glob(os.path.join(image_path, \"*.jpg\")):\n",
    "        if i % stride == 0:\n",
    "            img = cv2.imread(file_name)\n",
    "            height, width = img.shape[:2]\n",
    "            images.append(cv2.resize(img, (int(width / 2), int(height / 2))))\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    for label_txt in glob.glob(os.path.join(label_path, \"*.txt\")):\n",
    "        if i % stride == 0:\n",
    "            with open(label_txt) as f:\n",
    "                labels.append(int(f.readlines()[0].split(\" \")[0]))\n",
    "        i += 1\n",
    "            \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50193cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "stride = 16\n",
    "train_X, train_y = import_yolo_data(data_dir, \"train\", stride)\n",
    "val_X, val_y = import_yolo_data(data_dir, \"val\", stride)\n",
    "test_X, test_y = import_yolo_data(data_dir, \"test\", stride)\n",
    "\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed224fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = OneHotEncoder().fit_transform(np.array(train_y).reshape(-1,1)).reshape(-1, 4).toarray()\n",
    "val_y = OneHotEncoder().fit_transform(np.array(val_y).reshape(-1,1)).reshape(-1, 4).toarray()\n",
    "test_y = OneHotEncoder().fit_transform(np.array(test_y).reshape(-1,1)).reshape(-1, 4).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389049f0",
   "metadata": {},
   "source": [
    "# model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a4a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialising the CNN\n",
    "# classifier = Sequential()\n",
    "\n",
    "# # Step 1 - Convolution\n",
    "# classifier.add(Convolution2D(32, (3, 3), input_shape = (720, 128, 3), activation = 'relu'))\n",
    "\n",
    "# # Step 2 - Pooling\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# # Adding a second convolutional layer\n",
    "# classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# # Adding a third convolutional layer\n",
    "# classifier.add(Convolution2D(64, (3, 3), activation = 'relu'))          # 64 feature detectors, can be changed to something else\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# # Adding a fourth convolutional layer\n",
    "# classifier.add(Convolution2D(64, (3, 3), activation = 'relu'))          # 64 feature detectors, can be changed to something else\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# # Step 3 - Flattening\n",
    "# classifier.add(Flatten())\n",
    "\n",
    "# # Step 4 - Full connection\n",
    "# classifier.add(Dense(units = 128, activation = 'relu', use_bias=True, bias_initializer='ones'))\n",
    "# classifier.add(Dropout(0.5))\n",
    "# classifier.add(Dense(units = 5, activation = 'softmax', use_bias=True, bias_initializer='ones'))\n",
    "\n",
    "# # Compiling the CNN\n",
    "# classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "def create_model(dropout_rate=0.0):\n",
    "    model = Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), input_shape = (360, 640, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation = 'relu', use_bias=True, bias_initializer='ones'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4, activation = 'softmax', use_bias=True, bias_initializer='ones'),\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model, dropout_rate=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d84251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.create_model(dropout_rate=0.0)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'dropout_rate': 0.2,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30724e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(epochs=[5], optimizer=['SGD', 'Nadam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86a5903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [5], 'optimizer': ['SGD', 'Nadam']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91963027",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=1, cv=3, scoring=\"accuracy\", verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e211419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:39:03.594674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:03.759705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:03.759754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:03.761273: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 10:39:03.765789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:03.765849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:03.765865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:04.660588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:04.661053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:04.661066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-12-20 10:39:04.661101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-20 10:39:04.661134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5400 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:39:06.690705: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700\n",
      "2022-12-20 10:39:08.117589: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 163ms/step - loss: 66.2145 - accuracy: 0.2600\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 4.6274 - accuracy: 0.2200\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.9666 - accuracy: 0.2850\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.2530 - accuracy: 0.2850\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.7693 - accuracy: 0.2900\n",
      "4/4 [==============================] - 0s 70ms/step\n",
      "[CV 1/3] END ...........epochs=5, optimizer=SGD;, score=0.220 total time=  10.2s\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 47.8758 - accuracy: 0.2050\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.8980 - accuracy: 0.1900\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.2259 - accuracy: 0.2550\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.9881 - accuracy: 0.2650\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.7091 - accuracy: 0.3050\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "[CV 2/3] END ...........epochs=5, optimizer=SGD;, score=0.250 total time=   3.9s\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 39.6979 - accuracy: 0.2450\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 3.7724 - accuracy: 0.2900\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.0591 - accuracy: 0.2350\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.6337 - accuracy: 0.3350\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.5571 - accuracy: 0.4500\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "[CV 3/3] END ...........epochs=5, optimizer=SGD;, score=0.220 total time=   3.9s\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 37.2194 - accuracy: 0.2250\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 3.2139 - accuracy: 0.2450\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.9959 - accuracy: 0.2400\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.0208 - accuracy: 0.2650\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.8491 - accuracy: 0.2400\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "[CV 1/3] END .........epochs=5, optimizer=Nadam;, score=0.280 total time=   4.0s\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 47.6292 - accuracy: 0.2700\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.2189 - accuracy: 0.2400\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.6399 - accuracy: 0.3800\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.5545 - accuracy: 0.4400\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.4828 - accuracy: 0.5650\n",
      "4/4 [==============================] - 0s 24ms/step\n",
      "[CV 2/3] END .........epochs=5, optimizer=Nadam;, score=0.190 total time=   4.0s\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 97ms/step - loss: 46.6213 - accuracy: 0.2600\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 2.0217 - accuracy: 0.2000\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.8437 - accuracy: 0.2350\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.7337 - accuracy: 0.2550\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.7094 - accuracy: 0.2600\n",
      "4/4 [==============================] - 0s 25ms/step\n",
      "[CV 3/3] END .........epochs=5, optimizer=Nadam;, score=0.270 total time=   4.0s\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 2s 164ms/step - loss: 33.8932 - accuracy: 0.1733\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.6733 - accuracy: 0.2533\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7407 - accuracy: 0.2467\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6968 - accuracy: 0.2767\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6696 - accuracy: 0.2867\n"
     ]
    }
   ],
   "source": [
    "grid_result = clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd100279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(dropout_rate=0.2, model=&lt;function create_model at 0x7f2873ff0a60&gt;),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;epochs&#x27;: [5], &#x27;optimizer&#x27;: [&#x27;SGD&#x27;, &#x27;Nadam&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(dropout_rate=0.2, model=&lt;function create_model at 0x7f2873ff0a60&gt;),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;epochs&#x27;: [5], &#x27;optimizer&#x27;: [&#x27;SGD&#x27;, &#x27;Nadam&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_model at 0x7f2873ff0a60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tdropout_rate=0.2\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_model at 0x7f2873ff0a60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tdropout_rate=0.2\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(dropout_rate=0.2, model=<function create_model at 0x7f2873ff0a60>),\n",
       "             n_jobs=1,\n",
       "             param_grid={'epochs': [5], 'optimizer': ['SGD', 'Nadam']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db974b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.246667 using {'epochs': 5, 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1af539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.230000 (0.014142) with: {'epochs': 5, 'optimizer': 'SGD'}\n",
      "0.246667 (0.040277) with: {'epochs': 5, 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb6808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e12f10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8bb3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4766666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21700fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([5.76779087, 3.80925488]),\n",
       " 'std_fit_time': array([2.88325457, 0.03174408]),\n",
       " 'mean_score_time': array([0.24187247, 0.18285362]),\n",
       " 'std_score_time': array([0.0785797 , 0.00382419]),\n",
       " 'param_epochs': masked_array(data=[5, 5],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['SGD', 'Nadam'],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'epochs': 5, 'optimizer': 'SGD'},\n",
       "  {'epochs': 5, 'optimizer': 'Nadam'}],\n",
       " 'split0_test_score': array([0.22, 0.28]),\n",
       " 'split1_test_score': array([0.25, 0.19]),\n",
       " 'split2_test_score': array([0.22, 0.27]),\n",
       " 'mean_test_score': array([0.23      , 0.24666667]),\n",
       " 'std_test_score': array([0.01414214, 0.04027682]),\n",
       " 'rank_test_score': array([2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d34985a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e49b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_model at 0x7f2873ff0a60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tdropout_rate=0.2\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function create_model at 0x7f2873ff0a60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tdropout_rate=0.2\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function create_model at 0x7f2873ff0a60>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tdropout_rate=0.2\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a348e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
